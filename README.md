# ğŸš€ Desafio de Nivelamento â€“ Intuitive Care

Este repositÃ³rio contÃ©m a soluÃ§Ã£o desenvolvida para o desafio tÃ©cnico, com o objetivo de demonstrar habilidades em:

- Web scraping com Python ğŸ•·ï¸  
- TransformaÃ§Ã£o e limpeza de dados ğŸ§¹  
- CriaÃ§Ã£o e manipulaÃ§Ã£o de banco de dados PostgreSQL ğŸ—ƒï¸  
- Desenvolvimento de API com Flask ğŸ”Œ  
- CriaÃ§Ã£o de uma interface web com Vue.js ğŸŒ  

---

## ğŸ§© DescriÃ§Ã£o do Projeto

O desafio teve como objetivo o desenvolvimento de uma aplicaÃ§Ã£o completa capaz de:

1. **Extrair dados da web** utilizando tÃ©cnicas de web scraping com Python.
2. **Transformar e organizar os dados** extraÃ­dos para uso estruturado.
3. **Persistir os dados em um banco de dados relacional (PostgreSQL)**, criando as tabelas e estruturas necessÃ¡rias.
4. **Desenvolver uma API REST com Flask**, capaz de acessar dados em um arquivo CSV.
5. **Construir uma interface web em Vue.js** para exibir os dados consultados pela API de forma clara e interativa para o usuÃ¡rio.

---

## ğŸ› ï¸ Tecnologias Utilizadas

### Backend
- **Python 3.10+**
- **Flask** (API REST)
- **BeautifulSoup / Requests** (Web Scraping)
- **Pandas** (TransformaÃ§Ã£o de dados)
- **SQLAlchemy** (ORM para PostgreSQL)
- **PostgreSQL 10+**

### Frontend
- **Vue.js 3**
- **Axios** (Consumo da API)
- **Vite** (Empacotamento)

---

## ğŸ“ Estrutura do Projeto



---

## ğŸš€ Como Executar o Projeto

### 1. Clonar o repositÃ³rio
```bash
git clone https://github.com/seu-usuario/desafio-nivelamento.git
cd desafio-nivelamento
```

### 2. Instalar dependÃªncias do backend
```bash
cd backend
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate no Windows
pip install -r requirements.txt
```

### 3. Iniciar a API Flask
```bash
python app.py
```

### 3. Rodar o frontend
```bash
cd ../frontend
npm install
npm run dev
```

---

## ğŸ” Funcionalidades Implementadas

- ğŸ” Busca por registros via interface (consumindo o CSV ou banco)
- ğŸ“Š VisualizaÃ§Ã£o dos dados estruturados
- ğŸ“¥ ExtraÃ§Ã£o de informaÃ§Ãµes via scraping automatizado
- ğŸ”„ AtualizaÃ§Ã£o e ingestÃ£o de dados no PostgreSQL
- ğŸ” Arquitetura separada por camadas (scraper, API, frontend)

---

## ğŸ’¬ ConsideraÃ§Ãµes Finais

Esse desafio foi uma excelente oportunidade de aplicar conhecimentos prÃ¡ticos em todo o ciclo de desenvolvimento de uma aplicaÃ§Ã£o fullstack orientada a dados. As etapas de scraping, limpeza, persistÃªncia, API e exibiÃ§Ã£o foram fundamentais para consolidar a integraÃ§Ã£o entre backend e frontend com foco em dados reais.

---
